/**
 * Collect derivatives for Batch 2 roots from words table
 */

import { createClient } from '@supabase/supabase-js';
import * as dotenv from 'dotenv';
import * as path from 'path';
import * as fs from 'fs';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

dotenv.config({ path: path.resolve(process.cwd(), '.env.local') });

const supabase = createClient(process.env.VITE_SUPABASE_URL!, process.env.VITE_SUPABASE_ANON_KEY!);

interface DerivativeWord {
  hebrew: string;
  ipa: string;
  korean: string;
  meaning: string;
  grammar: string;
}

interface RootData {
  root: string;
  root_hebrew: string;
  strong_number: string;
  etymology_simple: string;
  derivatives: DerivativeWord[];
}

async function collectDerivatives() {
  console.log('ğŸ” Batch 2 íŒŒìƒì–´ ìˆ˜ì§‘ ì‹œì‘\n');
  console.log('â”'.repeat(80) + '\n');

  // 1. etymology_simple ë°ì´í„° ë¡œë“œ
  const etymologyPath = path.join(__dirname, 'batch2_etymology_simple.json');
  const etymologyData = JSON.parse(fs.readFileSync(etymologyPath, 'utf-8'));

  const results: RootData[] = [];

  // 2. ê° ì–´ê·¼ì˜ íŒŒìƒì–´ ìˆ˜ì§‘
  for (const root of etymologyData.roots) {
    console.log(`ğŸ“ ${root.root} (${root.root_hebrew}) ì²˜ë¦¬ ì¤‘...`);

    // words í…Œì´ë¸”ì—ì„œ í•´ë‹¹ ì–´ê·¼ì„ ê°€ì§„ ë‹¨ì–´ë“¤ ì¡°íšŒ
    const { data: words, error } = await supabase
      .from('words')
      .select('hebrew, ipa, korean, meaning, grammar, root')
      .or(`root.ilike.%${root.root}%,root.ilike.%${root.root_hebrew}%`)
      .limit(10);

    if (error) {
      console.error(`   âŒ ì¡°íšŒ ì‹¤íŒ¨:`, error.message);
      continue;
    }

    if (!words || words.length === 0) {
      console.log(`   âš ï¸  íŒŒìƒì–´ ì—†ìŒ`);
      results.push({
        root: root.root,
        root_hebrew: root.root_hebrew,
        strong_number: root.strong_number,
        etymology_simple: root.etymology_simple,
        derivatives: []
      });
      continue;
    }

    // ì¤‘ë³µ ì œê±° (íˆë¸Œë¦¬ì–´ ê¸°ì¤€)
    const uniqueWords = new Map<string, any>();
    words.forEach(w => {
      if (!uniqueWords.has(w.hebrew)) {
        uniqueWords.set(w.hebrew, w);
      }
    });

    // ìµœëŒ€ 5ê°œ ì„ íƒ
    const derivatives: DerivativeWord[] = Array.from(uniqueWords.values())
      .slice(0, 5)
      .map(w => ({
        hebrew: w.hebrew,
        ipa: w.ipa,
        korean: w.korean,
        meaning: w.meaning,
        grammar: w.grammar
      }));

    console.log(`   âœ… íŒŒìƒì–´ ${derivatives.length}ê°œ ìˆ˜ì§‘`);
    derivatives.forEach((d, idx) => {
      console.log(`      ${idx + 1}. ${d.hebrew} (${d.korean}) - ${d.meaning}`);
    });
    console.log('');

    results.push({
      root: root.root,
      root_hebrew: root.root_hebrew,
      strong_number: root.strong_number,
      etymology_simple: root.etymology_simple,
      derivatives
    });
  }

  // 3. JSON íŒŒì¼ë¡œ ì €ì¥
  const outputPath = path.join(__dirname, 'batch2_complete_data.json');
  const outputData = {
    collected_at: new Date().toISOString().split('T')[0],
    batch: 2,
    roots_count: results.length,
    roots: results
  };

  fs.writeFileSync(outputPath, JSON.stringify(outputData, null, 2), 'utf-8');

  console.log('â”'.repeat(80));
  console.log(`\nâœ… Batch 2 ìˆ˜ì§‘ ì™„ë£Œ!`);
  console.log(`ğŸ“ ì €ì¥ ìœ„ì¹˜: ${outputPath}`);
  console.log(`ğŸ“Š ì´ ${results.length}ê°œ ì–´ê·¼`);
  console.log(`ğŸ“– ì´ ${results.reduce((sum, r) => sum + r.derivatives.length, 0)}ê°œ íŒŒìƒì–´\n`);
}

collectDerivatives().catch(console.error);
