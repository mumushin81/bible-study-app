#!/usr/bin/env tsx

import { createHash } from 'crypto'
import { readFileSync, readdirSync } from 'fs'
import { join } from 'path'

const JPG_DIR = join(process.cwd(), 'output', 'all_words_jpg')

interface FileInfo {
  filename: string
  size: number
  hash: string
}

function getFileHash(filepath: string): string {
  const content = readFileSync(filepath)
  return createHash('md5').update(content).digest('hex')
}

function analyzeDuplicates() {
  console.log('ğŸ” ì¤‘ë³µ ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘\n')

  const files = readdirSync(JPG_DIR).filter(f => f.endsWith('.jpg'))
  console.log(`ğŸ“ ì´ ${files.length}ê°œ JPG íŒŒì¼ ë°œê²¬\n`)

  // íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
  const fileInfos: FileInfo[] = []
  for (const filename of files) {
    const filepath = join(JPG_DIR, filename)
    const size = readFileSync(filepath).length
    const hash = getFileHash(filepath)
    fileInfos.push({ filename, size, hash })
  }

  // í¬ê¸°ë³„ ê·¸ë£¹í™”
  const sizeGroups = new Map<number, FileInfo[]>()
  for (const info of fileInfos) {
    if (!sizeGroups.has(info.size)) {
      sizeGroups.set(info.size, [])
    }
    sizeGroups.get(info.size)!.push(info)
  }

  // í•´ì‹œë³„ ê·¸ë£¹í™”
  const hashGroups = new Map<string, FileInfo[]>()
  for (const info of fileInfos) {
    if (!hashGroups.has(info.hash)) {
      hashGroups.set(info.hash, [])
    }
    hashGroups.get(info.hash)!.push(info)
  }

  // ì¤‘ë³µ ì°¾ê¸° (ë™ì¼í•œ í•´ì‹œ)
  const duplicates: Array<{ hash: string; files: FileInfo[] }> = []
  for (const [hash, files] of hashGroups.entries()) {
    if (files.length > 1) {
      duplicates.push({ hash, files })
    }
  }

  console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
  console.log('ğŸ“Š ì¤‘ë³µ ë¶„ì„ ê²°ê³¼\n')

  console.log(`ì´ íŒŒì¼: ${files.length}ê°œ`)
  console.log(`ê³ ìœ  í•´ì‹œ: ${hashGroups.size}ê°œ`)
  console.log(`ì¤‘ë³µ ê·¸ë£¹: ${duplicates.length}ê°œ\n`)

  if (duplicates.length > 0) {
    console.log('âŒ ì¤‘ë³µëœ ì´ë¯¸ì§€ ë°œê²¬:\n')

    let totalDuplicateFiles = 0
    for (let i = 0; i < Math.min(duplicates.length, 10); i++) {
      const dup = duplicates[i]
      totalDuplicateFiles += dup.files.length - 1
      console.log(`[${i + 1}] ì¤‘ë³µ ê·¸ë£¹ (${dup.files.length}ê°œ íŒŒì¼):`)
      console.log(`    í•´ì‹œ: ${dup.hash}`)
      console.log(`    í¬ê¸°: ${Math.round(dup.files[0].size / 1024)} KB`)
      dup.files.forEach(f => {
        console.log(`    - ${f.filename}`)
      })
      console.log('')
    }

    if (duplicates.length > 10) {
      console.log(`... ê·¸ ì™¸ ${duplicates.length - 10}ê°œ ì¤‘ë³µ ê·¸ë£¹ ë” ìˆìŒ\n`)
    }

    console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`)
    console.log(`âš ï¸  ì´ ${totalDuplicateFiles}ê°œ ì¤‘ë³µ íŒŒì¼ ë°œê²¬`)
    console.log(`ğŸ’¾ ì¤‘ë³µ ì œê±° ì‹œ ì ˆì•½ ê°€ëŠ¥: ~${Math.round((totalDuplicateFiles * dup.files[0].size) / 1024 / 1024 * 100) / 100} MB`)
  } else {
    console.log('âœ… ì¤‘ë³µëœ ì´ë¯¸ì§€ ì—†ìŒ')
  }
  console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n')

  // í¬ê¸° ë¶„í¬ ë¶„ì„
  const sizeDistribution = new Map<number, number>()
  for (const info of fileInfos) {
    const sizeKB = Math.round(info.size / 1024)
    sizeDistribution.set(sizeKB, (sizeDistribution.get(sizeKB) || 0) + 1)
  }

  console.log('ğŸ“Š íŒŒì¼ í¬ê¸° ë¶„í¬:')
  const sortedSizes = Array.from(sizeDistribution.entries()).sort((a, b) => b[1] - a[1])
  for (let i = 0; i < Math.min(sortedSizes.length, 10); i++) {
    const [sizeKB, count] = sortedSizes[i]
    console.log(`  ${sizeKB} KB: ${count}ê°œ`)
  }
  console.log('')

  return { duplicates, totalFiles: files.length, uniqueHashes: hashGroups.size }
}

analyzeDuplicates()
