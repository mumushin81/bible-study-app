/**
 * Fix Duplicate Data in words Table
 *
 * Automatically finds and removes duplicate (verse_id, position) entries
 * Keeps the oldest record (first created), deletes the rest
 */

import { createClient } from '@supabase/supabase-js'
import * as dotenv from 'dotenv'
import * as path from 'path'

// Load environment variables
dotenv.config({ path: path.join(process.cwd(), '.env.local') })

const supabaseUrl = process.env.VITE_SUPABASE_URL
const supabaseKey = process.env.VITE_SUPABASE_ANON_KEY

if (!supabaseUrl || !supabaseKey) {
  console.error('âŒ Missing Supabase credentials in .env.local')
  process.exit(1)
}

const supabase = createClient(supabaseUrl, supabaseKey)

interface DuplicateWord {
  verse_id: string
  position: number
  count: number
  ids: string[]
  created_ats: string[]
  hebrew_words: string[]
}

async function findDuplicates(): Promise<DuplicateWord[]> {
  console.log('\nğŸ” 1ë‹¨ê³„: ì¤‘ë³µ ë°ì´í„° ì°¾ëŠ” ì¤‘...\n')

  // Fetch all words
  const { data: words, error } = await supabase
    .from('words')
    .select('id, verse_id, position, hebrew, created_at')
    .order('verse_id')
    .order('position')

  if (error) {
    console.error('âŒ Error fetching words:', error)
    throw error
  }

  if (!words || words.length === 0) {
    console.log('âš ï¸  No words found in database')
    return []
  }

  // Group by verse_id and position
  const grouped = new Map<string, typeof words>()

  for (const word of words) {
    const key = `${word.verse_id}:${word.position}`
    if (!grouped.has(key)) {
      grouped.set(key, [])
    }
    grouped.get(key)!.push(word)
  }

  // Find duplicates
  const duplicates: DuplicateWord[] = []

  for (const [key, wordGroup] of grouped.entries()) {
    if (wordGroup.length > 1) {
      const [verse_id, position] = key.split(':')
      duplicates.push({
        verse_id,
        position: parseInt(position),
        count: wordGroup.length,
        ids: wordGroup.map(w => w.id),
        created_ats: wordGroup.map(w => w.created_at),
        hebrew_words: wordGroup.map(w => w.hebrew)
      })
    }
  }

  return duplicates
}

async function deleteDuplicates(duplicates: DuplicateWord[]): Promise<number> {
  console.log('\nğŸ—‘ï¸  2ë‹¨ê³„: ì¤‘ë³µ ë°ì´í„° ì‚­ì œ ì¤‘...\n')

  let totalDeleted = 0

  for (const dup of duplicates) {
    // Sort by created_at to keep the oldest
    const sorted = dup.ids
      .map((id, idx) => ({ id, created_at: dup.created_ats[idx] }))
      .sort((a, b) => a.created_at.localeCompare(b.created_at))

    // Keep the first (oldest), delete the rest
    const toKeep = sorted[0].id
    const toDelete = sorted.slice(1).map(x => x.id)

    console.log(`ğŸ“ ${dup.verse_id} position ${dup.position}:`)
    console.log(`   ìœ ì§€: ${toKeep} (ìƒì„±: ${sorted[0].created_at})`)
    console.log(`   ì‚­ì œ: ${toDelete.length}ê°œ`)

    // Delete duplicates
    for (const id of toDelete) {
      const { error } = await supabase
        .from('words')
        .delete()
        .eq('id', id)

      if (error) {
        console.error(`   âŒ Failed to delete ${id}:`, error.message)
      } else {
        totalDeleted++
        console.log(`   âœ… ì‚­ì œ ì„±ê³µ: ${id}`)
      }
    }
  }

  return totalDeleted
}

async function verifyNoDuplicates(): Promise<boolean> {
  console.log('\nâœ… 3ë‹¨ê³„: ì¤‘ë³µ ì œê±° í™•ì¸ ì¤‘...\n')

  const duplicates = await findDuplicates()

  if (duplicates.length === 0) {
    console.log('âœ… ì¤‘ë³µ ë°ì´í„° ì—†ìŒ - ì •ë¦¬ ì™„ë£Œ!')
    return true
  } else {
    console.log(`âŒ ì•„ì§ ${duplicates.length}ê°œì˜ ì¤‘ë³µì´ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤:`)
    for (const dup of duplicates) {
      console.log(`   - ${dup.verse_id} position ${dup.position} (${dup.count}ê°œ)`)
    }
    return false
  }
}

async function main() {
  console.log('ğŸš€ ì¤‘ë³µ ë°ì´í„° ìë™ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸')
  console.log('=' .repeat(50))

  try {
    // Step 1: Find duplicates
    const duplicates = await findDuplicates()

    if (duplicates.length === 0) {
      console.log('\nâœ… ì¤‘ë³µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!')
      console.log('ğŸ‘‰ ì´ì œ unique constraintë¥¼ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n')
      return
    }

    console.log(`ğŸ“Š ë°œê²¬ëœ ì¤‘ë³µ: ${duplicates.length}ê°œ\n`)
    for (const dup of duplicates) {
      console.log(`   - ${dup.verse_id} position ${dup.position}`)
      console.log(`     ê°œìˆ˜: ${dup.count}ê°œ`)
      console.log(`     ë‹¨ì–´: ${dup.hebrew_words.join(', ')}`)
    }

    // Step 2: Delete duplicates
    const deleted = await deleteDuplicates(duplicates)
    console.log(`\nğŸ“Š ì´ ${deleted}ê°œì˜ ì¤‘ë³µ ë ˆì½”ë“œ ì‚­ì œë¨`)

    // Step 3: Verify
    const success = await verifyNoDuplicates()

    if (success) {
      console.log('\nğŸ‰ ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ!')
      console.log('\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:')
      console.log('Supabase SQL Editorì—ì„œ ë‹¤ìŒ SQLì„ ì‹¤í–‰í•˜ì„¸ìš”:')
      console.log('https://supabase.com/dashboard/project/ouzlnriafovnxlkywerk/sql/new\n')
      console.log('-- Unique ì œì•½ ì¡°ê±´ ì¶”ê°€')
      console.log('ALTER TABLE words')
      console.log('  ADD CONSTRAINT unique_word_position')
      console.log('  UNIQUE (verse_id, position);')
      console.log('')
      console.log('ALTER TABLE verses')
      console.log('  ADD CONSTRAINT unique_verse_reference')
      console.log('  UNIQUE (book_id, chapter, verse_number);')
      console.log('')
    } else {
      console.log('\nâš ï¸  ì¼ë¶€ ì¤‘ë³µì´ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ë³´ì„¸ìš”.')
    }

  } catch (error) {
    console.error('\nâŒ Error:', error)
    process.exit(1)
  }
}

main()
